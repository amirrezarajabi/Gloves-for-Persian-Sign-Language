{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4b2ce75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04c95d3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3488e417",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_line(line):\n",
    "    return [float(i) for i in line[:-1].split(\" \")]\n",
    "\n",
    "def read_file(path):\n",
    "    with open(path, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "    X = [[]]\n",
    "    for i in range(len(lines)):\n",
    "        if \";\" in lines[i]:\n",
    "            X.append([])\n",
    "        else:\n",
    "            X[-1].append(prepare_line(lines[i]))\n",
    "    if X[-1] == []:\n",
    "        return X[:-1]\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa74898c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./data/Baba.txt',\n",
       " './data/Khosh.txt',\n",
       " './data/MohandesBadMohandes.txt',\n",
       " './data/Ast.txt',\n",
       " './data/MohandesBakht.txt',\n",
       " './data/AstMohandesAst.txt',\n",
       " './data/AstMohandes.txt',\n",
       " './data/BakhtAstMobark.txt',\n",
       " './data/MohandesAst.txt',\n",
       " './data/BakhtKhoshMobark.txt',\n",
       " './data/BadAstMobark.txt',\n",
       " './data/BabaMobark.txt',\n",
       " './data/BadMohandes.txt',\n",
       " './data/KhoshKhosh.txt',\n",
       " './data/KhoshKhoshBaba.txt',\n",
       " './data/MobarkKhosh.txt',\n",
       " './data/MohandesBabaAst.txt',\n",
       " './data/AstBad.txt',\n",
       " './data/BakhtKhosh.txt',\n",
       " './data/AstKhosh.txt',\n",
       " './data/MohandesBabaMohandes.txt',\n",
       " './data/MobarkBadBakht.txt',\n",
       " './data/MobarkKhoshBad.txt',\n",
       " './data/BabaKhoshKhosh.txt',\n",
       " './data/MobarkAst.txt',\n",
       " './data/BabaBaba.txt',\n",
       " './data/BakhtBad.txt',\n",
       " './data/KhoshAst.txt',\n",
       " './data/MohandesKhosh.txt',\n",
       " './data/KhoshMobark.txt',\n",
       " './data/MohandesBaba.txt',\n",
       " './data/MohandesBabaBakht.txt',\n",
       " './data/BabaBabaKhosh.txt',\n",
       " './data/KhoshBad.txt',\n",
       " './data/KhoshAstAst.txt',\n",
       " './data/KhoshMohandesBad.txt',\n",
       " './data/MohandesBakhtBad.txt',\n",
       " './data/KhoshMohandes.txt',\n",
       " './data/BadBad.txt',\n",
       " './data/BakhtMohandes.txt',\n",
       " './data/AstBakhtMobark.txt',\n",
       " './data/BakhtKhoshMohandes.txt',\n",
       " './data/BadAst.txt',\n",
       " './data/MobarkMohandesAst.txt',\n",
       " './data/MobarkBad.txt',\n",
       " './data/AstMobark.txt',\n",
       " './data/KhoshBaba.txt',\n",
       " './data/BadKhosh.txt',\n",
       " './data/BabaMohandes.txt',\n",
       " './data/BabaBadMobark.txt',\n",
       " './data/BadBakht.txt',\n",
       " './data/BabaMobarkMohandes.txt',\n",
       " './data/BakhtAst.txt',\n",
       " './data/MohandesBabaBaba.txt',\n",
       " './data/BadKhoshAst.txt',\n",
       " './data/BabaBabaAst.txt',\n",
       " './data/MobarkKhoshBaba.txt',\n",
       " './data/MobarkBadBaba.txt',\n",
       " './data/MohandesBad.txt',\n",
       " './data/BadBaba.txt',\n",
       " './data/BabaBakht.txt',\n",
       " './data/Mohandes.txt',\n",
       " './data/BakhtAstBakht.txt',\n",
       " './data/MohandesBadBad.txt',\n",
       " './data/BadMobark.txt',\n",
       " './data/AstBaba.txt',\n",
       " './data/MobarkMobark.txt',\n",
       " './data/MobarkBakht.txt',\n",
       " './data/BadBakhtKhosh.txt',\n",
       " './data/BakhtBakht.txt',\n",
       " './data/BabaAst.txt',\n",
       " './data/BakhtMobark.txt',\n",
       " './data/BabaBad.txt',\n",
       " './data/Bad.txt',\n",
       " './data/BadBakhtMohandes.txt',\n",
       " './data/BabaMobarkAst.txt',\n",
       " './data/AstKhoshAst.txt',\n",
       " './data/AstBakht.txt',\n",
       " './data/BabaBadAst.txt',\n",
       " './data/BabaKhoshBakht.txt',\n",
       " './data/MobarkMobarkBad.txt',\n",
       " './data/Bakht.txt',\n",
       " './data/BakhtBaba.txt',\n",
       " './data/MohandesMobark.txt',\n",
       " './data/MobarkMohandesMohandes.txt',\n",
       " './data/MobarkMobarkBaba.txt',\n",
       " './data/KhoshAstBad.txt',\n",
       " './data/BakhtBadAst.txt',\n",
       " './data/MohandesKhoshKhosh.txt',\n",
       " './data/MobarkBadMohandes.txt',\n",
       " './data/Mobark.txt',\n",
       " './data/BadBadMohandes.txt',\n",
       " './data/AstKhoshBaba.txt',\n",
       " './data/MobarkBaba.txt',\n",
       " './data/MobarkMohandes.txt',\n",
       " './data/KhoshBadMohandes.txt',\n",
       " './data/MohandesMobarkAst.txt',\n",
       " './data/BabaBakhtBad.txt',\n",
       " './data/AstAst.txt',\n",
       " './data/BabaKhosh.txt']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder = \"./data/\"\n",
    "files = [folder + f for f in os.listdir(folder)]\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef7cd12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = [\n",
    "    \"Ast\",\n",
    "    \"Baba\",\n",
    "    \"Bad\",\n",
    "    \"Bakht\",\n",
    "    \"Khosh\",\n",
    "    \"Mobark\",\n",
    "    \"Mohandes\",\n",
    "]\n",
    "\n",
    "CLASSES2INDEX = {k:v for v,k in enumerate(CLASSES)}\n",
    "\n",
    "INDEX2CLASSES = {v:k for v,k in enumerate(CLASSES)}\n",
    "\n",
    "def output_ctc(output):\n",
    "    ans = \"\"\n",
    "    tmp = \"\" if output[0] == \"_\" else output[0]\n",
    "    ans = ans + tmp\n",
    "    for i in range(len(output)):\n",
    "        if output[i] != tmp and output[i] != \"_\":\n",
    "            tmp = output[i]\n",
    "            ans = ans + tmp\n",
    "        if output[i] == \"_\":\n",
    "            tmp = output[i]\n",
    "    return ans\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "import re\n",
    "\n",
    "def line2float(line: str):\n",
    "        return [float(i) for i in line[:-1].split(\" \")]\n",
    "    \n",
    "def read_file(file:str):\n",
    "    with open(file, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "    x = [[]]\n",
    "    for i in range(len(lines)):\n",
    "        if \";\" in lines[i]:\n",
    "            x.append([])\n",
    "        else:\n",
    "            x[-1].append(line2float(lines[i]))\n",
    "    if x[-1] == []:\n",
    "        return x[:-1]\n",
    "    return x\n",
    "\n",
    "def file2data(file: str, data):\n",
    "        X = read_file(file=file)\n",
    "        y = file.split(\"/\")[-1].split(\".\")[0] if \"/\" in file else file.split(\".\")[0]\n",
    "        y = re.findall('[A-Z][^A-Z]*', y)\n",
    "        for x in X:\n",
    "            data.append([np.array(x), [CLASSES2INDEX[move] for move in y]])\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "95f91ef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "352"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "for f in files:\n",
    "    data = file2data(f, data)\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0b5cbea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "BLANK = len(CLASSES)\n",
    "def pad_x(x, length):\n",
    "    return np.pad(x, ((0, length - x.shape[0]), (0, 0)), mode='constant', constant_values = 0.)\n",
    "\n",
    "def pad_y(y, length):\n",
    "    out = [i for i in y]\n",
    "    for i in range(length - len(y)):\n",
    "        out.append(BLANK)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3529d887",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_batch(data, index, bs):\n",
    "    last_index = min(len(data), (index + 1) * bs)\n",
    "    batch = data[index * bs: last_index]\n",
    "    max_x = max([d[0].shape[0] for d in batch])\n",
    "    max_y = max([len(d[1]) for d in batch])\n",
    "    X = []\n",
    "    y = []\n",
    "    target_lengths = []\n",
    "    for d in batch:\n",
    "        X.append(pad_x(d[0], max_x))\n",
    "        y.append(pad_y(d[1], max_y))\n",
    "        target_lengths.append(len(d[1]))\n",
    "    y = np.array(y)\n",
    "    X = np.array(X)\n",
    "    X = torch.from_numpy(X).float().to(device)\n",
    "    y = torch.from_numpy(y).int().to(device)\n",
    "    target_lengths = torch.from_numpy(np.array(target_lengths)).int().to(device)\n",
    "    return X, y, target_lengths, len(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "af58c2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ad0de9ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(264, 88)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SPLIT = 0.75\n",
    "split_index = int(SPLIT * len(data))\n",
    "train = data[:split_index]\n",
    "test = data[split_index:]\n",
    "len(train), len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b7f7575e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11, 62, 10])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_batch(train, 0, 11)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f5db5053",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1223345'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def output_ctc(out):\n",
    "    s = \"\"\n",
    "    tmp = \"\" if out[0] == \"_\" else out[0]\n",
    "    s = s + tmp\n",
    "    for i in range(len(out)):\n",
    "        if out[i] != tmp and out[i] != \"_\":\n",
    "            tmp = out[i]\n",
    "            s = s + tmp\n",
    "        if out[i] == \"_\":\n",
    "            tmp = out[i]\n",
    "    return s\n",
    "output_ctc(\"__11112__233_333_4__5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8fcd70a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def score(yhat, answer):\n",
    "    s = 0\n",
    "    for i in range(min(len(yhat), len(answer))):\n",
    "        s += yhat[i] == answer[i]\n",
    "    return s\n",
    "score(\"356\", \"45\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "decbb4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_SIZE1 = 64\n",
    "HIDDEN_SIZE2 = 128\n",
    "HIDDEN_SIZE3 = 256\n",
    "HIDDEN_SIZE4 = 32\n",
    "D, NL = 1, 1\n",
    "NUM_CLASS = BLANK + 1\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.rnn1 = nn.LSTM(10, HIDDEN_SIZE1, NL, batch_first=True)\n",
    "        self.rnn2 = nn.LSTM(D*HIDDEN_SIZE1, HIDDEN_SIZE2, NL, batch_first=True)\n",
    "        self.rnn3 = nn.LSTM(D*HIDDEN_SIZE2, HIDDEN_SIZE3, NL, batch_first=True)\n",
    "        self.L1 = nn.Linear(D * HIDDEN_SIZE3, HIDDEN_SIZE4)\n",
    "        self.L2 = nn.Linear(HIDDEN_SIZE4, NUM_CLASS)\n",
    "    def forward(self, x):\n",
    "        out, _ = self.rnn1(x) # (N, L, D*HIDDEN_SIZE)\n",
    "        #print(out.shape)\n",
    "        out, _ = self.rnn2(out) # (N, L, D*HIDDEN_SIZE)\n",
    "        #print(out.shape)\n",
    "        out, _ = self.rnn3(out) # (N, L, D*HIDDEN_SIZE)\n",
    "        #print(out.shape)\n",
    "        l , bs = out.shape[1], out.shape[0]\n",
    "        #print(out.shape)\n",
    "        out = self.L1(out)\n",
    "        #print(out.shape)\n",
    "        out = nn.Sigmoid()(out)\n",
    "        out = self.L2(out)\n",
    "        #print(out.shape)\n",
    "        out = out.transpose(0, 1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c364e6dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([46, 5, 8]), 522536)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = Model().to(device)\n",
    "m(extract_batch(train, 0, 5)[0]).shape, sum(p.numel() for p in m.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6f472737",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = sorted(train, key=lambda x: len(x[1]), reverse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cbad1f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 1e-3\n",
    "EPOCH = 100\n",
    "BATCH_SIZE = 11\n",
    "model = Model().to(device)\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=LR)\n",
    "criterion = nn.CTCLoss(blank=BLANK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b57e903",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|██████████████████████████████████████████████████████████████████████████▊              | 84/100 [01:14<00:12,  1.31it/s]"
     ]
    }
   ],
   "source": [
    "LOSS = []\n",
    "model.train()\n",
    "for ep in tqdm(range(1, EPOCH + 1)):\n",
    "    LOSS.append(0)\n",
    "    np.random.shuffle(train)\n",
    "    for b in range(len(train) // BATCH_SIZE):\n",
    "        X, y, target_lengths, bs = extract_batch(train, b, BATCH_SIZE)\n",
    "        optimizer.zero_grad()\n",
    "        yp = model(X)\n",
    "        yp = nn.functional.log_softmax(yp, dim=2)\n",
    "        input_lengths = torch.LongTensor([yp.shape[0]] * bs).to(device)\n",
    "        loss = criterion(yp, y, input_lengths, target_lengths)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        with torch.no_grad():\n",
    "            LOSS[-1] += (float(loss) / (len(train) // BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7717bd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(list(range(1, len(LOSS) + 1)), LOSS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc0a805",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(data, model_for_eval, bs, erorr=False):\n",
    "    acc, tot, word_acc, word_tot = 0, 0, 0, len(data)\n",
    "    L = len(data) // bs\n",
    "    ERORRS = []\n",
    "    for l in tqdm(range(L)):\n",
    "        X, y, _, _ = extract_batch(data, l, bs)\n",
    "        model_for_eval.eval()\n",
    "        with torch.no_grad():\n",
    "            yp = model_for_eval(X)\n",
    "            yp = nn.functional.log_softmax(yp, dim=2)\n",
    "            for j in range(bs):\n",
    "                ypp = torch.argmax(yp[:, j, :], dim=1)\n",
    "                ypp = list(ypp)\n",
    "                s = \"\"\n",
    "                for i in ypp:\n",
    "                    if i == 2:\n",
    "                        s = s + \"_\"\n",
    "                    else:\n",
    "                        s = s + str(int(i))\n",
    "                ans = [str(int(e)) for e in y[j]]\n",
    "                ans = [a for a in ans if a != \"2\"]\n",
    "                ans = \"\".join(ans)\n",
    "                s = output_ctc(s)\n",
    "                if erorr and s != ans:\n",
    "                    ERORRS.append([s, ans, data[l * bs + j][0], l * bs + j])\n",
    "                word_acc += ans == s\n",
    "                tot += len(ans)\n",
    "                for cahr in range(len(ans)):\n",
    "                    if cahr >= len(s):\n",
    "                        break\n",
    "                    acc += s[cahr] == ans[cahr]\n",
    "    if erorr:\n",
    "        return word_acc / word_tot, acc / tot, ERORRS  \n",
    "    return word_acc / word_tot , acc / tot\n",
    "evaluate(train, model, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1727518f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, _, _ = extract_batch(train, b, BATCH_SIZE)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    yp = model(X)\n",
    "    yp = nn.functional.log_softmax(yp, dim=2)\n",
    "    for j in range(BATCH_SIZE):\n",
    "        ypp = torch.argmax(yp[:, j, :], dim=1)\n",
    "        ypp = list(ypp)\n",
    "        s = \"\"\n",
    "        for i in ypp:\n",
    "            if i == 2:\n",
    "                s = s + \"_\"\n",
    "            else:\n",
    "                s = s + str(int(i))\n",
    "        ans = \"\".join([str(int(e)) for e in y[j] if int(e) != 2])\n",
    "        print(f\"{output_ctc(s)} : {ans} ---> {ans == output_ctc(s)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2ef36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(test, model, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcded68",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, _, _ = extract_batch(test, 0, BATCH_SIZE)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    yp = model(X)\n",
    "    yp = nn.functional.log_softmax(yp, dim=2)\n",
    "    for j in range(BATCH_SIZE):\n",
    "        ypp = torch.argmax(yp[:, j, :], dim=1)\n",
    "        ypp = list(ypp)\n",
    "        s = \"\"\n",
    "        for i in ypp:\n",
    "            if i == 2:\n",
    "                s = s + \"_\"\n",
    "            else:\n",
    "                s = s + str(int(i))\n",
    "        ans = \"\".join([str(int(e)) for e in y[j] if int(e) != 2])\n",
    "        print(f\"{output_ctc(s)} : {ans} ---> {ans == output_ctc(s)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
