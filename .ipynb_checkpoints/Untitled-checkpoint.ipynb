{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4b2ce75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04c95d3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3488e417",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_line(line):\n",
    "    return [float(i) for i in line[:-1].split(\" \")]\n",
    "\n",
    "def read_file(path):\n",
    "    with open(path, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "    X = [[]]\n",
    "    for i in range(len(lines)):\n",
    "        if \";\" in lines[i]:\n",
    "            X.append([])\n",
    "        else:\n",
    "            X[-1].append(prepare_line(lines[i]))\n",
    "    if X[-1] == []:\n",
    "        return X[:-1]\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa74898c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./data/Baba.txt',\n",
       " './data/Khosh.txt',\n",
       " './data/MohandesBadMohandes.txt',\n",
       " './data/Ast.txt',\n",
       " './data/MohandesBakht.txt',\n",
       " './data/AstMohandesAst.txt',\n",
       " './data/AstMohandes.txt',\n",
       " './data/BakhtAstMobark.txt',\n",
       " './data/MohandesAst.txt',\n",
       " './data/BakhtKhoshMobark.txt',\n",
       " './data/BadAstMobark.txt',\n",
       " './data/BabaMobark.txt',\n",
       " './data/BadMohandes.txt',\n",
       " './data/KhoshKhosh.txt',\n",
       " './data/KhoshKhoshBaba.txt',\n",
       " './data/MobarkKhosh.txt',\n",
       " './data/MohandesBabaAst.txt',\n",
       " './data/AstBad.txt',\n",
       " './data/BakhtKhosh.txt',\n",
       " './data/AstKhosh.txt',\n",
       " './data/MohandesBabaMohandes.txt',\n",
       " './data/MobarkBadBakht.txt',\n",
       " './data/MobarkKhoshBad.txt',\n",
       " './data/BabaKhoshKhosh.txt',\n",
       " './data/MobarkAst.txt',\n",
       " './data/BabaBaba.txt',\n",
       " './data/BakhtBad.txt',\n",
       " './data/KhoshAst.txt',\n",
       " './data/MohandesKhosh.txt',\n",
       " './data/KhoshMobark.txt',\n",
       " './data/MohandesBaba.txt',\n",
       " './data/MohandesBabaBakht.txt',\n",
       " './data/BabaBabaKhosh.txt',\n",
       " './data/KhoshBad.txt',\n",
       " './data/KhoshAstAst.txt',\n",
       " './data/KhoshMohandesBad.txt',\n",
       " './data/MohandesBakhtBad.txt',\n",
       " './data/KhoshMohandes.txt',\n",
       " './data/BadBad.txt',\n",
       " './data/BakhtMohandes.txt',\n",
       " './data/AstBakhtMobark.txt',\n",
       " './data/BakhtKhoshMohandes.txt',\n",
       " './data/BadAst.txt',\n",
       " './data/MobarkMohandesAst.txt',\n",
       " './data/MobarkBad.txt',\n",
       " './data/AstMobark.txt',\n",
       " './data/KhoshBaba.txt',\n",
       " './data/BadKhosh.txt',\n",
       " './data/BabaMohandes.txt',\n",
       " './data/BabaBadMobark.txt',\n",
       " './data/BadBakht.txt',\n",
       " './data/BabaMobarkMohandes.txt',\n",
       " './data/BakhtAst.txt',\n",
       " './data/MohandesBabaBaba.txt',\n",
       " './data/BadKhoshAst.txt',\n",
       " './data/BabaBabaAst.txt',\n",
       " './data/MobarkKhoshBaba.txt',\n",
       " './data/MobarkBadBaba.txt',\n",
       " './data/MohandesBad.txt',\n",
       " './data/BadBaba.txt',\n",
       " './data/BabaBakht.txt',\n",
       " './data/Mohandes.txt',\n",
       " './data/BakhtAstBakht.txt',\n",
       " './data/MohandesBadBad.txt',\n",
       " './data/BadMobark.txt',\n",
       " './data/AstBaba.txt',\n",
       " './data/MobarkMobark.txt',\n",
       " './data/MobarkBakht.txt',\n",
       " './data/BadBakhtKhosh.txt',\n",
       " './data/BakhtBakht.txt',\n",
       " './data/BabaAst.txt',\n",
       " './data/BakhtMobark.txt',\n",
       " './data/BabaBad.txt',\n",
       " './data/Bad.txt',\n",
       " './data/BadBakhtMohandes.txt',\n",
       " './data/BabaMobarkAst.txt',\n",
       " './data/AstKhoshAst.txt',\n",
       " './data/AstBakht.txt',\n",
       " './data/BabaBadAst.txt',\n",
       " './data/BabaKhoshBakht.txt',\n",
       " './data/MobarkMobarkBad.txt',\n",
       " './data/Bakht.txt',\n",
       " './data/BakhtBaba.txt',\n",
       " './data/MohandesMobark.txt',\n",
       " './data/MobarkMohandesMohandes.txt',\n",
       " './data/MobarkMobarkBaba.txt',\n",
       " './data/KhoshAstBad.txt',\n",
       " './data/BakhtBadAst.txt',\n",
       " './data/MohandesKhoshKhosh.txt',\n",
       " './data/MobarkBadMohandes.txt',\n",
       " './data/Mobark.txt',\n",
       " './data/BadBadMohandes.txt',\n",
       " './data/AstKhoshBaba.txt',\n",
       " './data/MobarkBaba.txt',\n",
       " './data/MobarkMohandes.txt',\n",
       " './data/KhoshBadMohandes.txt',\n",
       " './data/MohandesMobarkAst.txt',\n",
       " './data/BabaBakhtBad.txt',\n",
       " './data/AstAst.txt',\n",
       " './data/BabaKhosh.txt']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder = \"./data/\"\n",
    "files = [folder + f for f in os.listdir(folder)]\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ef7cd12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "B: 0\n",
    "H: 1\n",
    "\"\"\"\n",
    "\n",
    "CHAR2LABEL = {\n",
    "    \"B\": 0,\n",
    "    \"H\": 1\n",
    "}\n",
    "\n",
    "def file2data(path, data):\n",
    "    X = read_file(path)\n",
    "    label = path.split(\"/\")[-1].split(\".\")[0]\n",
    "    for x in X:\n",
    "        data.append([np.array(x), [CHAR2LABEL[char] for char in label]])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "95f91ef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "167"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "for f in files:\n",
    "    data = file2data(f, data)\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0b5cbea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "BLANK = 2\n",
    "def pad_x(x, length):\n",
    "    return np.pad(x, ((0, length - x.shape[0]), (0, 0)), mode='constant', constant_values = 0.)\n",
    "\n",
    "def pad_y(y, length):\n",
    "    out = [i for i in y]\n",
    "    for i in range(length - len(y)):\n",
    "        out.append(BLANK)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3529d887",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_batch(data, index, bs):\n",
    "    last_index = min(len(data), (index + 1) * bs)\n",
    "    batch = data[index * bs: last_index]\n",
    "    max_x = max([d[0].shape[0] for d in batch])\n",
    "    max_y = max([len(d[1]) for d in batch])\n",
    "    X = []\n",
    "    y = []\n",
    "    target_lengths = []\n",
    "    for d in batch:\n",
    "        X.append(pad_x(d[0], max_x))\n",
    "        y.append(pad_y(d[1], max_y))\n",
    "        target_lengths.append(len(d[1]))\n",
    "    y = np.array(y)\n",
    "    X = np.array(X)\n",
    "    X = torch.from_numpy(X).float().to(device)\n",
    "    y = torch.from_numpy(y).int().to(device)\n",
    "    target_lengths = torch.from_numpy(np.array(target_lengths)).int().to(device)\n",
    "    return X, y, target_lengths, len(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "af58c2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ad0de9ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(133, 34)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SPLIT = 0.8\n",
    "split_index = int(SPLIT * len(data))\n",
    "train = data[:split_index]\n",
    "test = data[split_index:]\n",
    "len(train), len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b7f7575e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 28, 10])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_batch(train, 0, 5)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f5db5053",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1223345'"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def output_ctc(out):\n",
    "    s = \"\"\n",
    "    tmp = \"\" if out[0] == \"_\" else out[0]\n",
    "    s = s + tmp\n",
    "    for i in range(len(out)):\n",
    "        if out[i] != tmp and out[i] != \"_\":\n",
    "            tmp = out[i]\n",
    "            s = s + tmp\n",
    "        if out[i] == \"_\":\n",
    "            tmp = out[i]\n",
    "    return s\n",
    "output_ctc(\"__11112__233_333_4__5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "8fcd70a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def score(yhat, answer):\n",
    "    s = 0\n",
    "    for i in range(min(len(yhat), len(answer))):\n",
    "        s += yhat[i] == answer[i]\n",
    "    return s\n",
    "score(\"356\", \"45\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "decbb4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_SIZE1 = 64\n",
    "HIDDEN_SIZE2 = 128\n",
    "HIDDEN_SIZE3 = 256\n",
    "HIDDEN_SIZE4 = 32\n",
    "D, NL = 1, 1\n",
    "NUM_CLASS = BLANK + 1\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.rnn1 = nn.LSTM(10, HIDDEN_SIZE1, NL, batch_first=True)\n",
    "        self.rnn2 = nn.LSTM(D*HIDDEN_SIZE1, HIDDEN_SIZE2, NL, batch_first=True)\n",
    "        self.rnn3 = nn.LSTM(D*HIDDEN_SIZE2, HIDDEN_SIZE3, NL, batch_first=True)\n",
    "        self.L1 = nn.Linear(D * HIDDEN_SIZE3, HIDDEN_SIZE4)\n",
    "        self.L2 = nn.Linear(HIDDEN_SIZE4, NUM_CLASS)\n",
    "    def forward(self, x):\n",
    "        out, _ = self.rnn1(x) # (N, L, D*HIDDEN_SIZE)\n",
    "        #print(out.shape)\n",
    "        out, _ = self.rnn2(out) # (N, L, D*HIDDEN_SIZE)\n",
    "        #print(out.shape)\n",
    "        out, _ = self.rnn3(out) # (N, L, D*HIDDEN_SIZE)\n",
    "        #print(out.shape)\n",
    "        l , bs = out.shape[1], out.shape[0]\n",
    "        #print(out.shape)\n",
    "        out = self.L1(out)\n",
    "        #print(out.shape)\n",
    "        out = nn.Sigmoid()(out)\n",
    "        out = self.L2(out)\n",
    "        #print(out.shape)\n",
    "        out = out.transpose(0, 1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "c364e6dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([42, 5, 3]), 522371)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = Model().to(device)\n",
    "m(extract_batch(train, 0, 5)[0]).shape, sum(p.numel() for p in m.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "6f472737",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = sorted(train, key=lambda x: len(x[1]), reverse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "cbad1f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 1e-3\n",
    "EPOCH = 200\n",
    "BATCH_SIZE = 19\n",
    "model = Model().to(device)\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=LR)\n",
    "criterion = nn.CTCLoss(blank=BLANK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "1b57e903",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 200/200 [03:52<00:00,  1.16s/it]\n"
     ]
    }
   ],
   "source": [
    "LOSS = []\n",
    "model.train()\n",
    "for ep in tqdm(range(1, EPOCH + 1)):\n",
    "    LOSS.append(0)\n",
    "    np.random.shuffle(train)\n",
    "    for b in range(len(train) // BATCH_SIZE):\n",
    "        X, y, target_lengths, bs = extract_batch(train, b, BATCH_SIZE)\n",
    "        optimizer.zero_grad()\n",
    "        yp = model(X)\n",
    "        yp = nn.functional.log_softmax(yp, dim=2)\n",
    "        input_lengths = torch.LongTensor([yp.shape[0]] * bs).to(device)\n",
    "        loss = criterion(yp, y, input_lengths, target_lengths)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        with torch.no_grad():\n",
    "            LOSS[-1] += (float(loss) / (len(train) // BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "7717bd01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1ea0d1b98b0>]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(list(range(1, len(LOSS) + 1)), LOSS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "0fc0a805",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 22.29it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.49624060150375937, 0.6266094420600858)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def evaluate(data, model_for_eval, bs, erorr=False):\n",
    "    acc, tot, word_acc, word_tot = 0, 0, 0, len(data)\n",
    "    L = len(data) // bs\n",
    "    ERORRS = []\n",
    "    for l in tqdm(range(L)):\n",
    "        X, y, _, _ = extract_batch(data, l, bs)\n",
    "        model_for_eval.eval()\n",
    "        with torch.no_grad():\n",
    "            yp = model_for_eval(X)\n",
    "            yp = nn.functional.log_softmax(yp, dim=2)\n",
    "            for j in range(bs):\n",
    "                ypp = torch.argmax(yp[:, j, :], dim=1)\n",
    "                ypp = list(ypp)\n",
    "                s = \"\"\n",
    "                for i in ypp:\n",
    "                    if i == 2:\n",
    "                        s = s + \"_\"\n",
    "                    else:\n",
    "                        s = s + str(int(i))\n",
    "                ans = [str(int(e)) for e in y[j]]\n",
    "                ans = [a for a in ans if a != \"2\"]\n",
    "                ans = \"\".join(ans)\n",
    "                s = output_ctc(s)\n",
    "                if erorr and s != ans:\n",
    "                    ERORRS.append([s, ans, data[l * bs + j][0], l * bs + j])\n",
    "                word_acc += ans == s\n",
    "                tot += len(ans)\n",
    "                for cahr in range(len(ans)):\n",
    "                    if cahr >= len(s):\n",
    "                        break\n",
    "                    acc += s[cahr] == ans[cahr]\n",
    "    if erorr:\n",
    "        return word_acc / word_tot, acc / tot, ERORRS  \n",
    "    return word_acc / word_tot , acc / tot\n",
    "evaluate(train, model, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "1727518f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00 : 00 ---> True\n",
      "0 : 01 ---> False\n",
      "0 : 0 ---> True\n",
      "0 : 01 ---> False\n",
      "00 : 00 ---> True\n",
      "00 : 00 ---> True\n",
      "00 : 00 ---> True\n",
      "10 : 10 ---> True\n",
      " : 11 ---> False\n",
      "0 : 01 ---> False\n",
      "10 : 10 ---> True\n",
      " : 1 ---> False\n",
      "0 : 0 ---> True\n",
      "0 : 01 ---> False\n",
      "00 : 00 ---> True\n",
      "0 : 01 ---> False\n",
      "0 : 0 ---> True\n",
      "00 : 00 ---> True\n",
      "00 : 00 ---> True\n"
     ]
    }
   ],
   "source": [
    "X, y, _, _ = extract_batch(train, b, BATCH_SIZE)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    yp = model(X)\n",
    "    yp = nn.functional.log_softmax(yp, dim=2)\n",
    "    for j in range(BATCH_SIZE):\n",
    "        ypp = torch.argmax(yp[:, j, :], dim=1)\n",
    "        ypp = list(ypp)\n",
    "        s = \"\"\n",
    "        for i in ypp:\n",
    "            if i == 2:\n",
    "                s = s + \"_\"\n",
    "            else:\n",
    "                s = s + str(int(i))\n",
    "        ans = \"\".join([str(int(e)) for e in y[j] if int(e) != 2])\n",
    "        print(f\"{output_ctc(s)} : {ans} ---> {ans == output_ctc(s)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "bd2ef36a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 24.10it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5294117647058824, 0.6065573770491803)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(test, model, 17)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
